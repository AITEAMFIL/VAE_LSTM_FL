{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "def fxn():\n",
    "    warnings.warn(\"deprecated\", DeprecationWarning)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    fxn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib.pyplot import plot, ion, show, savefig, cla, figure\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from data_loader import DataGenerator\n",
    "from models import VAEmodel, lstmKerasModel\n",
    "from trainers import vaeTrainer\n",
    "\n",
    "from utils import process_config, create_dirs, get_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "print(get_available_gpus())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
      "\n",
      "ECG\n",
      "ECG\n",
      "ECG\n",
      "ECG\n",
      "ECG\n",
      "ECG\n",
      "ECG\n"
     ]
    }
   ],
   "source": [
    "# load VAE model\n",
    "config = process_config('NAB_config5.json')#('NAB_config_centralized.json')\n",
    "# create the experiments dirs\n",
    "create_dirs([config['result_dir'], config['checkpoint_dir']])\n",
    "# create tensorflow session\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "# create your data generator\n",
    "\n",
    "data = DataGenerator(config)\n",
    "# create a CNN model\n",
    "model_vae = VAEmodel(config, \"Global\")\n",
    "# create a CNN model\n",
    "trainer_vae = vaeTrainer(sess, model_vae, data, config)\n",
    "model_vae.load(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['config', 'n_train_vae', 'n_val_vae', 'train_set_vae', 'val_set_vae', 'test_set_vae', 'n_train_lstm', 'n_val_lstm', 'train_set_lstm', 'val_set_lstm'])\n",
      "n_train_vae 11312\n",
      "n_val_vae 1257\n",
      "n_train_lstm 11074\n",
      "n_val_lstm 1231\n",
      "train_set_vae (11312, 24, 1)\n",
      "val_set_vae (1257, 24, 1)\n",
      "test_set_vae (32, 24, 1)\n",
      "train_set_lstm (11074, 12, 24, 1)\n",
      "val_set_lstm (1231, 12, 24, 1)\n"
     ]
    }
   ],
   "source": [
    "print(data.__dict__.keys())\n",
    "for i in data.__dict__.keys():\n",
    "    if (i not in ['config','train_set_vae','val_set_vae','test_set_vae','train_set_lstm', 'val_set_lstm']):\n",
    "        print(i ,getattr(data,i))\n",
    "for i in  ['train_set_vae','val_set_vae','test_set_vae','train_set_lstm', 'val_set_lstm']:\n",
    "    print(i ,(getattr(data,i)['data']).shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nprs44'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['dataset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load LSTM model\n",
    "lstm_model = lstmKerasModel(\"Global\", config)\n",
    "lstm_model.produce_embeddings(model_vae, data, sess)\n",
    "lstm_nn_model = lstm_model.create_lstm_model()\n",
    "lstm_nn_model.summary()   # Display the model's architecture\n",
    "\n",
    "# checkpoint path\n",
    "checkpoint_path = config['checkpoint_dir_lstm'] + \"cp_Global.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "# load weights if possible\n",
    "lstm_model.load_model(lstm_nn_model, checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The given sequence has 1841 samples\n",
      "test_windows  (1818, 24, 2)\n",
      "test_seq  (1554, 12, 24, 2)\n"
     ]
    }
   ],
   "source": [
    "# load normalised time series\n",
    "save_dir = '../datasets/NAB-known-anomaly/'\n",
    "config['dataset'] = 'ecg_1'\n",
    "dataset = config['dataset']\n",
    "filename = '{}.npz'.format(dataset)\n",
    "result = dict(np.load(save_dir+filename, allow_pickle=True))\n",
    "if dataset == 'machine_temp':\n",
    "    result['test'] = result['test'][0]\n",
    "    result['idx_anomaly_test'] = result['idx_anomaly_test'][0]\n",
    "    result['t_test'] = result['t_test'][0]\n",
    "\n",
    "# slice into rolling windows and rolling sequences\n",
    "# slice into rolling windows and rolling sequences\n",
    "def slice_rolling_windows_and_sequences(config, time_seq):\n",
    "    n_sample = len(time_seq)\n",
    "    time_seq = np.reshape(time_seq,(-1,config['n_channel']))\n",
    "    print(\"The given sequence has {} samples\".format(n_sample))\n",
    "    n_vae_win = n_sample - config['l_win'] + 1\n",
    "    rolling_windows = np.zeros((n_vae_win, config['l_win'], config['n_channel']))\n",
    "    for i in range(n_vae_win):\n",
    "        rolling_windows[i] = time_seq[i:i + config['l_win']]\n",
    "        sample_m = np.mean(rolling_windows, axis=1)\n",
    "        sample_std = np.std(rolling_windows, axis=1)\n",
    "\n",
    "        n_lstm_seq = n_sample - config['l_seq']*config['l_win']+1\n",
    "        lstm_seq = np.zeros((n_lstm_seq, config['l_seq'], config['l_win'], config['n_channel']))\n",
    "    for i in range(n_lstm_seq):\n",
    "        cur_seq = time_seq[i:i+config['l_seq']*config['l_win']]\n",
    "        for j in range(config['l_seq']):\n",
    "            lstm_seq[i,j] = cur_seq[config['l_win']*j:config['l_win']*(j+1)]\n",
    "    \n",
    "    return rolling_windows, lstm_seq, sample_m, sample_std\n",
    "\n",
    "test_windows, test_seq, test_sample_m, test_sample_std = slice_rolling_windows_and_sequences(config, result['test'])\n",
    "test_windows = np.reshape(test_windows, (-1,config['l_win'],config['n_channel']))\n",
    "test_seq = np.reshape(test_seq, (-1,config['l_seq'],config['l_win'],config['n_channel']))\n",
    "print('test_windows ',test_windows.shape)\n",
    "print('test_seq ',test_seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'readings': array([[-0.645,  0.665],\n",
       "        [-0.635,  0.71 ],\n",
       "        [-0.645,  0.745],\n",
       "        ...,\n",
       "        [-0.435, -0.07 ],\n",
       "        [-0.445, -0.06 ],\n",
       "        [-0.435, -0.07 ]]),\n",
       " 'idx_anomaly': array([2331, 2332, 2333, 2334, 2335, 2336, 2337, 2338, 2339, 2340, 2341,\n",
       "        2342, 2343, 2344, 2345, 2346, 2347, 2348, 2349, 2350, 2351, 2352,\n",
       "        2353, 2354, 2355, 2356, 2357, 2358, 2359, 2360, 2361, 2362, 2363,\n",
       "        2364, 2365, 2366, 2367, 2368, 2369, 2370, 2371, 2372, 2373, 2374,\n",
       "        2375, 2376, 2377, 2378, 2379, 2380, 2381, 2382, 2383, 2384, 2385,\n",
       "        2386, 2387, 2388, 2389, 2390, 2391, 2392, 2393, 2394, 2395, 2396,\n",
       "        2397, 2398, 2399, 2400, 2401, 2402, 2403, 2404, 2405, 2406, 2407,\n",
       "        2408, 2409, 2410, 2411, 2412, 2413, 2414, 2415, 2416, 2417, 2418,\n",
       "        2419, 2420, 2421, 2422, 2423, 2424, 2425, 2426, 2427, 2428, 2429,\n",
       "        2430, 2431, 2432, 2433, 2434, 2435, 2436, 2437, 2438, 2439, 2440,\n",
       "        2441, 2442, 2443, 2444, 2445, 2446, 2447, 2448, 2449, 2450, 2451,\n",
       "        2452, 2453, 2454, 2455, 2456, 2457, 2458, 2459, 2460, 2461, 2462,\n",
       "        2463, 2464, 2465, 2466, 2467, 2468, 2469, 2470, 2471, 2472, 2473,\n",
       "        2474, 2475, 2476, 2477, 2478, 2479, 2480, 2481, 2482, 2483, 2484,\n",
       "        2485, 2486, 2487, 2488, 2489, 2490, 2491, 2492, 2493, 2494, 2495,\n",
       "        2496, 2497, 2498, 2499, 2500, 2501, 2502, 2503, 2504, 2505, 2506,\n",
       "        2507, 2508, 2509, 2510, 2511, 2512, 2513, 2514, 2515, 2516, 2517,\n",
       "        2518, 2519, 2520, 2521, 2522, 2523, 2524, 2525, 2526, 2527, 2528,\n",
       "        2529, 2530, 2531, 2532, 2533, 2534, 2535, 2536, 2537, 2538, 2539,\n",
       "        2540, 2541, 2542, 2543, 2544, 2545, 2546, 2547, 2548, 2549, 2550,\n",
       "        2551, 2552, 2553, 2554, 2555, 2556, 2557, 2558, 2559, 2560, 2561,\n",
       "        2562, 2563, 2564, 2565, 2566, 2567, 2568, 2569, 2570, 2571, 2572,\n",
       "        2573, 2574, 2575, 2576, 2577, 2578, 2579, 2580, 2581, 2582, 2583,\n",
       "        2584, 2585, 2586, 2587, 2588, 2589, 2590, 2591, 2592, 2593, 2594,\n",
       "        2595, 2596, 2597, 2598, 2599]),\n",
       " 'training': array([[-0.9291369 ,  1.00323889],\n",
       "        [-0.8963574 ,  1.05544038],\n",
       "        [-0.9291369 ,  1.09604155],\n",
       "        ...,\n",
       "        [-1.22415237,  0.95683756],\n",
       "        [-1.20776262,  0.98003822],\n",
       "        [-1.14220363,  1.00323889]]),\n",
       " 'test': array([[-1.17498312,  1.04384005],\n",
       "        [-1.10942413,  1.03803988],\n",
       "        [-1.09303438,  1.06704072],\n",
       "        ...,\n",
       "        [-0.66690092,  0.99743872],\n",
       "        [-0.63412142,  0.99163856],\n",
       "        [-0.65051117,  1.01483922]]),\n",
       " 'train_m': array([-0.36154937, -0.19983633]),\n",
       " 'train_std': array([0.30506875, 0.86204427]),\n",
       " '_train': array([   1,    2,    3, ..., 1831, 1832, 1833]),\n",
       " 't_test': array([   1,    2,    3, ..., 1839, 1840, 1841]),\n",
       " 'idx_anomaly_test': array([498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510,\n",
       "        511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523,\n",
       "        524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536,\n",
       "        537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549,\n",
       "        550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562,\n",
       "        563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575,\n",
       "        576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588,\n",
       "        589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601,\n",
       "        602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614,\n",
       "        615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627,\n",
       "        628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640,\n",
       "        641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653,\n",
       "        654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666,\n",
       "        667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679,\n",
       "        680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692,\n",
       "        693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705,\n",
       "        706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718,\n",
       "        719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731,\n",
       "        732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744,\n",
       "        745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757,\n",
       "        758, 759, 760, 761, 762, 763, 764, 765, 766])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate ELBO and LSTM prediction error on the validation set\n",
    "# evaluate some anomaly detection metrics\n",
    "def evaluate_vae_anomaly_metrics_for_a_window(test_win):\n",
    "    feed_dict = {model_vae.original_signal: np.expand_dims(test_win, 0),\n",
    "                 model_vae.is_code_input: False,\n",
    "                 model_vae.code_input: np.zeros((1, config['code_size']))}\n",
    "\n",
    "    # VAE reconstruction error\n",
    "    recons_win_vae = np.squeeze(sess.run(model_vae.decoded, feed_dict=feed_dict))\n",
    "    test_vae_recons_error = np.sum(np.square(recons_win_vae - test_win))\n",
    "\n",
    "    # VAE latent embedding likelihood\n",
    "    vae_code_mean, vae_code_std = sess.run([model_vae.code_mean, model_vae.code_std_dev], feed_dict=feed_dict)\n",
    "    test_vae_kl = 0.5 * (np.sum(np.square(vae_code_mean)) + \\\n",
    "                            np.sum(np.square(vae_code_std)) - \\\n",
    "                            np.sum(np.log(np.square(vae_code_std))) - config['code_size'])\n",
    "\n",
    "    # VAE ELBO loss\n",
    "    sigma2 = 0.0005\n",
    "    input_dims = model_vae.input_dims\n",
    "    sigma_regularisor = input_dims/2. * np.log(sigma2) + input_dims * np.pi\n",
    "    test_vae_elbo = test_vae_recons_error/sigma2 + test_vae_kl + sigma_regularisor\n",
    "    return test_vae_recons_error, test_vae_kl, test_vae_elbo\n",
    "\n",
    "def evaluate_lstm_anomaly_metric_for_a_seq(test_seq):\n",
    "    feed_dict = {model_vae.original_signal: test_seq,\n",
    "                 model_vae.is_code_input: False,\n",
    "                 model_vae.code_input: np.zeros((1, config['code_size']))}\n",
    "    vae_embedding = np.squeeze(sess.run(model_vae.code_mean, feed_dict=feed_dict))\n",
    "    #print(vae_embedding.shape)\n",
    "    lstm_embedding = np.squeeze(lstm_nn_model.predict(np.expand_dims(vae_embedding[:config['l_seq']-1], 0), batch_size=1))\n",
    "    lstm_embedding_error = np.sum(np.square(vae_embedding[1:] - lstm_embedding))\n",
    "    # error_original = vae_embedding[1:] - lstm_embedding\n",
    "    #print(error_original.shape)\n",
    "    \n",
    "    # LSTM prediction error\n",
    "    feed_dict_lstm = {model_vae.original_signal: np.zeros((config['l_seq'] - 1, config['l_win'], config['n_channel'])),\n",
    "                      model_vae.is_code_input: True,\n",
    "                      model_vae.code_input: lstm_embedding}\n",
    "    recons_win_lstm = np.squeeze(sess.run(model_vae.decoded, feed_dict=feed_dict_lstm))\n",
    "    lstm_recons_error = np.sum(np.square(recons_win_lstm - np.squeeze(test_seq[1:])))\n",
    "    error_original = np.abs(recons_win_lstm - np.squeeze(test_seq[1:])).reshape((config['l_seq']-1,-1)) #them dong nay de tinh\n",
    "    return lstm_recons_error, lstm_embedding_error, error_original\n",
    "data.val_set_vae['data'] = np.asarray(data.val_set_vae['data'])\n",
    "data.val_set_lstm['data'] = np.asarray(data.val_set_lstm['data'])\n",
    "data.train_set_lstm['data'] = np.asarray(data.train_set_lstm['data'])\n",
    "data.train_set_vae['data'] = np.asarray(data.train_set_vae['data'])\n",
    "n_val_vae = data.val_set_vae['data'].shape[0]\n",
    "n_val_lstm = data.val_set_lstm['data'].shape[0]\n",
    "\n",
    "val_vae_recons_error = np.zeros(n_val_vae)\n",
    "val_vae_kl_error = np.zeros(n_val_vae)\n",
    "val_vae_elbo_loss = np.zeros(n_val_vae)\n",
    "for i in range(n_val_vae):\n",
    "    val_vae_recons_error[i], val_vae_kl_error[i], val_vae_elbo_loss[i] = evaluate_vae_anomaly_metrics_for_a_window(data.val_set_vae['data'][i])\n",
    "\n",
    "val_lstm_recons_error, val_lstm_embedding_error = np.zeros(n_val_lstm), np.zeros(n_val_lstm)\n",
    "val_lstm_error_original = np.zeros((n_val_lstm,config['l_seq']-1,config['l_win']*config['n_channel']))\n",
    "for i in range(n_val_lstm):\n",
    "    val_lstm_recons_error[i], val_lstm_embedding_error[i], val_lstm_error_original[i] = evaluate_lstm_anomaly_metric_for_a_seq(data.val_set_lstm['data'][i])\n",
    "    \n",
    "n_train_lstm = data.train_set_lstm['data'].shape[0]\n",
    "train_lstm_recons_error, train_lstm_embedding_error = np.zeros(n_train_lstm), np.zeros(n_train_lstm)\n",
    "train_lstm_error_original = np.zeros((n_train_lstm,config['l_seq']-1,config['l_win']*config['n_channel'])) #them de tinh OCSVM\n",
    "for i in range(n_train_lstm):\n",
    "    train_lstm_recons_error[i], train_lstm_embedding_error[i], train_lstm_error_original[i] = evaluate_lstm_anomaly_metric_for_a_seq(data.train_set_lstm['data'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['l_seq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "def plot_histogram(test_anomaly_metric, n_bins, title, mean=None, std=None, xlim=None, saveplot=False):\n",
    "    test_anomaly_list = np.squeeze(np.ndarray.flatten(test_anomaly_metric))\n",
    "    his = plt.hist(test_anomaly_list, bins=n_bins, density=True)\n",
    "    if mean is None and std is None:\n",
    "        mean = np.mean(test_anomaly_list)\n",
    "        std = np.std(test_anomaly_list)\n",
    "        legend_label = None\n",
    "    else:\n",
    "        legend_label = 1\n",
    "    x_axis = np.arange(mean-5*std, mean+5*std, std/100)\n",
    "    plt.plot(x_axis, norm.pdf(x_axis,mean,std))\n",
    "    plt.title(title)\n",
    "    plt.xlabel('anomaly score value')\n",
    "    plt.ylabel('probability density')\n",
    "    if xlim is not None:\n",
    "        plt.xlim(0, xlim)\n",
    "    else:\n",
    "        plt.xlim(0, np.amax(test_anomaly_list))\n",
    "    if legend_label is None:\n",
    "        plt.legend(('Fitted Gaussian', 'histogram'))\n",
    "    else:\n",
    "        plt.legend(('normal data distribution','test data distribution (contain anomalies)'))\n",
    "    if saveplot:\n",
    "        savefig(config['result_dir']+'reconstruction_error_histogram.pdf')\n",
    "    else:\n",
    "        plt.show()\n",
    "    threshold_25 = np.percentile(test_anomaly_list, 25)\n",
    "    threshold_75 = np.percentile(test_anomaly_list, 75)\n",
    "    threshold_1 = np.percentile(test_anomaly_list, 99)\n",
    "    idx_large_error = np.squeeze(np.argwhere(test_anomaly_metric > threshold_1))\n",
    "#     print(his[0][-20:])\n",
    "#     print(his[1][-20:])\n",
    "    print(\"25% percentile: {}\".format(threshold_25))\n",
    "    print(\"75% percentile: {}\".format(threshold_75))\n",
    "#     print(\"Median: {}\".format(np.median(test_anomaly_list)))\n",
    "#     print(\"Mean: {}\".format(np.mean(test_anomaly_list)))\n",
    "#     print(\"Std dev: {}\".format(np.std(test_anomaly_list)))\n",
    "    print(\"These windows scored the top 1% of anomaly metric ({}): \\n{}\".format(threshold_1, idx_large_error))\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of VAE ELBO loss - validation set\n",
    "vae_elbo_m, vae_elbo_std = plot_histogram(val_vae_elbo_loss, 100, \n",
    "                                          'VAE ELBO error distribution on the val set', \n",
    "                                          mean=None, std=None, xlim=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of LSTM reconstruction error - train set \n",
    "#  --> to decide the anomaly detection threshold\n",
    "lstm_recons_m_train, lstm_recons_std_train = plot_histogram(train_lstm_recons_error, 100,  \n",
    "                                              'LSTM reconstruction error distribution on the train set', \n",
    "                                              mean=None, std=None, xlim=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Histogram of LSTM reconstruction error - validation set \n",
    "#  --> to decide the anomaly detection threshold\n",
    "lstm_recons_m_val, lstm_recons_std_val = plot_histogram(val_lstm_recons_error, 100,  \n",
    "                                              'LSTM reconstruction error distribution on the val set', \n",
    "                                              mean=None, std=None, xlim=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the anomaly metrics on the test windows and sequences\n",
    "n_test_lstm = test_seq.shape[0]\n",
    "\n",
    "test_lstm_recons_error, test_lstm_embedding_error = np.zeros(n_test_lstm), np.zeros(n_test_lstm)\n",
    "test_lstm_error_original = np.zeros((n_test_lstm,config['l_seq']-1,config['l_win']*config['n_channel']))\n",
    "for i in range(n_test_lstm):\n",
    "    test_lstm_recons_error[i], test_lstm_embedding_error[i], test_lstm_error_original[i] = evaluate_lstm_anomaly_metric_for_a_seq(test_seq[i])\n",
    "print(\"All windows' reconstruction error is computed.\")\n",
    "print(\"The total number of windows is {}\".format(len(test_lstm_recons_error)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of LSTM reconstruction error - test set \n",
    "#  --> to detect anomaly now\n",
    "_, _ = plot_histogram(test_lstm_recons_error, 100,\n",
    "                      'LSTM reconstruction error distribution on the test set', \n",
    "                      mean=lstm_recons_m_val, std=lstm_recons_std_val, xlim=None, saveplot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce the ground truth anomaly indices \n",
    "# if result['idx_split'][0] == 0:\n",
    "#     idx_anomaly_test = result['idx_anomaly_test']\n",
    "# else:\n",
    "#     idx_anomaly_test = result['idx_anomaly_test'][0]\n",
    "idx_anomaly_test = result['idx_anomaly_test']    \n",
    "anomaly_index_lstm = []\n",
    "test_labels_lstm = np.zeros(n_test_lstm)\n",
    "for i in range(len(idx_anomaly_test)):\n",
    "    idx_start = idx_anomaly_test[i]-(config['l_win']*config['l_seq']-1)\n",
    "    idx_end = idx_anomaly_test[i]+1\n",
    "    if idx_start < 0:\n",
    "        idx_start = 0\n",
    "    if idx_end > n_test_lstm:\n",
    "        idx_end = n_test_lstm\n",
    "    anomaly_index_lstm.append(np.arange(idx_start,idx_end))\n",
    "    test_labels_lstm[idx_start:idx_end] = 1\n",
    "    \n",
    "print(test_labels_lstm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result['idx_anomaly_test'])\n",
    "print(list(anomaly_index_lstm))\n",
    "print(test_labels_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_normal_idx = np.squeeze(np.argwhere(test_labels_lstm==0))\n",
    "test_anomaly_idx = np.squeeze(np.argwhere(test_labels_lstm==1))\n",
    "test_lstm_recons_error_normal = test_lstm_recons_error[test_normal_idx]\n",
    "test_lstm_recons_error_anomaly = test_lstm_recons_error[test_anomaly_idx]\n",
    "lstm_recons_m_test_normal = np.mean(test_lstm_recons_error_normal)\n",
    "lstm_recons_std_test_normal = np.std(test_lstm_recons_error_normal)\n",
    "lstm_recons_m_test_anomaly = np.mean(test_lstm_recons_error_anomaly)\n",
    "lstm_recons_std_test_anomaly = np.std(test_lstm_recons_error_anomaly)\n",
    "lstm_recons_m_test = np.mean(test_lstm_recons_error)\n",
    "lstm_recons_std_test = np.mean(test_lstm_recons_error)\n",
    "\n",
    "means = (lstm_recons_m_test_normal, lstm_recons_m_test_anomaly, lstm_recons_m_test, lstm_recons_m_train, lstm_recons_m_val)\n",
    "stds = (lstm_recons_std_test_normal, lstm_recons_std_test_anomaly, lstm_recons_std_test, lstm_recons_std_train, lstm_recons_std_val)\n",
    "for mean,std in zip(means,stds):\n",
    "    x_axis = np.arange(mean-5*std, mean+5*std, std/100)\n",
    "    #x_axis = np.arange(-10000,10000)\n",
    "    plt.plot(x_axis, norm.pdf(x_axis,mean,std))\n",
    "plt.legend(('test_norm', 'test_anomaly', 'test', 'train', 'val')) \n",
    "#plt.xscale('log')\n",
    "#plt.yscale('log')\n",
    "plt.title(\"Distribution of different sets on \" + config['dataset'])\n",
    "#print(lstm_recons_m_test,lstm_recons_std_test)\n",
    "#print(lstm_recons_m_val,lstm_recons_std_val)\n",
    "#print(lstm_recons_m_test_normal,lstm_recons_m_test_normal)\n",
    "print(means)\n",
    "print(stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_anomaly_idx_by_threshold(test_anomaly_metric, threshold):\n",
    "    test_list = np.squeeze(np.ndarray.flatten(test_anomaly_metric))\n",
    "    idx_error = np.squeeze(np.argwhere(test_anomaly_metric > threshold))\n",
    "    \n",
    "    if len(idx_error.shape) == 0:\n",
    "        idx_error = np.expand_dims(idx_error, 0)\n",
    "    \n",
    "    return list(idx_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_detected_idx(idx_detected_anomaly, anomaly_index):\n",
    "    n_anomaly = len(anomaly_index)\n",
    "    idx_detected_anomaly_extended = list(idx_detected_anomaly)\n",
    "    for i in range(n_anomaly):\n",
    "        #print(idx_detected_anomaly)\n",
    "        for j in idx_detected_anomaly:\n",
    "            if j in anomaly_index[i]:\n",
    "                in_original_detection = set(idx_detected_anomaly_extended)\n",
    "                currect_anomaly_win = set(anomaly_index[i])\n",
    "                idx_detected_anomaly_extended = idx_detected_anomaly_extended + list(currect_anomaly_win - in_original_detection)\n",
    "                #print(j)\n",
    "                break\n",
    "                \n",
    "    return list(np.sort(idx_detected_anomaly_extended))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_TP_TN_FP_FN(idx_detected_anomaly, anomaly_index, test_labels):\n",
    "    n_TP = 0\n",
    "    n_FP = 0\n",
    "    n_TN = 0\n",
    "    n_detection = len(idx_detected_anomaly)\n",
    "    for i in range(n_detection):\n",
    "        if test_labels[idx_detected_anomaly[i]] == 1:\n",
    "            n_TP = n_TP + 1\n",
    "        else:\n",
    "            n_FP = n_FP + 1 #both branch the same?\n",
    "\n",
    "    idx_undetected = list(set(np.arange(len(test_labels)))- set(idx_detected_anomaly))\n",
    "    n_FN = 0\n",
    "    for i in idx_undetected:\n",
    "        if test_labels[i] == 1:\n",
    "            n_FN = n_FN + 1\n",
    "        else:\n",
    "            n_TN = n_TN + 1\n",
    "\n",
    "    return n_TP, n_TN, n_FP, n_FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_precision_and_recall(idx_detected_anomaly, anomaly_index, test_labels):\n",
    "    # compute true positive\n",
    "    n_TP, n_TN, n_FP, n_FN = count_TP_TN_FP_FN(idx_detected_anomaly, anomaly_index, test_labels)\n",
    "\n",
    "    accuracy = (n_TP + n_TN) / (n_TP + n_TN + n_FP + n_FN)\n",
    "    if n_TP + n_FP == 0:\n",
    "        precision = 1\n",
    "    else:\n",
    "        precision = n_TP / (n_TP + n_FP)\n",
    "    recall = n_TP / (n_TP + n_FN)\n",
    "    if precision + recall == 0:\n",
    "        F1 = 0\n",
    "    else:\n",
    "        F1 = 2* (precision * recall)/(precision + recall)\n",
    "\n",
    "    return accuracy, precision, recall, F1, n_TP, n_TN, n_FP, n_FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_threshold = 25\n",
    "accuracy = np.zeros(n_threshold)\n",
    "precision = np.zeros(n_threshold)\n",
    "recall = np.zeros(n_threshold)\n",
    "F1 = np.zeros(n_threshold)\n",
    "accuracy_aug = np.zeros(n_threshold)\n",
    "precision_aug = np.zeros(n_threshold)\n",
    "recall_aug = np.zeros(n_threshold)\n",
    "F1_aug = np.zeros(n_threshold)\n",
    "i = 0\n",
    "threshold_list = np.linspace(np.amin(test_lstm_recons_error), np.amax(test_lstm_recons_error), n_threshold, endpoint=True)\n",
    "threshold_list = np.flip(threshold_list)\n",
    "for threshold in threshold_list:\n",
    "    #print(threshold_list[i])\n",
    "    idx_detection_lstm = return_anomaly_idx_by_threshold(test_lstm_recons_error, threshold)\n",
    "    accuracy[i], precision[i], recall[i], F1[i], _, _, _, _ = compute_precision_and_recall(idx_detection_lstm, \n",
    "                                                                           anomaly_index_lstm, \n",
    "                                                                           test_labels_lstm)\n",
    "    # augment the detection using the ground truth labels\n",
    "    # a method to discount the factor one anomaly appears in multiple consecutive windows\n",
    "    # introduced in \"Unsupervised anomaly detection via variational auto-encoder for seasonal kpis in web applications\"\n",
    "    idx_detection_lstm_augmented = augment_detected_idx(idx_detection_lstm, anomaly_index_lstm)\n",
    "    accuracy_aug[i], precision_aug[i], recall_aug[i], F1_aug[i], _, _, _, _ = compute_precision_and_recall(idx_detection_lstm_augmented, \n",
    "                                                                                       anomaly_index_lstm, \n",
    "                                                                                       test_labels_lstm)\n",
    "    i = i + 1\n",
    "    #print(precision, recall, F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best F1 score is {}\".format(np.amax(F1)))\n",
    "idx_best_threshold = np.squeeze(np.argwhere(F1 == np.amax(F1)))\n",
    "print(\"Best threshold is {}\".format(threshold_list[idx_best_threshold]))\n",
    "print(\"At this threshold, accuracy is {}, precision is {}, recall is {}\".format(accuracy[idx_best_threshold], precision[idx_best_threshold], recall[idx_best_threshold]))\n",
    "average_precision = np.sum(precision[1:] * (recall[1:] - recall[:-1]))\n",
    "print(\"Average precision is {}\".format(average_precision))\n",
    "\n",
    "print(\"\\nAugmented detection:\")\n",
    "print(\"Best F1 score is {}\".format(np.amax(F1_aug)))\n",
    "idx_best_threshold = np.squeeze(np.argwhere(F1_aug == np.amax(F1_aug)))\n",
    "print(\"Best threshold is {}\".format(threshold_list[idx_best_threshold]))\n",
    "best_thres = np.min(threshold_list[idx_best_threshold])\n",
    "print(\"At this threshold, accuracy is {}, precision is {}, recall is {}\".format(accuracy_aug[idx_best_threshold], precision_aug[idx_best_threshold], \n",
    "                                                                recall_aug[idx_best_threshold]))\n",
    "\n",
    "average_precision_aug = np.sum(precision_aug[1:] * (recall_aug[1:] - recall_aug[:-1]))\n",
    "print(\"Average precision is {}\".format(average_precision_aug))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from scipy.stats import norm\n",
    "\n",
    "def KQp(data,q):\n",
    "#UNTITLED3 Summary of this function goes here\n",
    "#   Detailed explanation goes here\n",
    "    data2 = np.sort(data) #sap xep tang dan\n",
    "    n = np.shape(data2)[0] #kich thuoc\n",
    "    p = 1-q #q tu xet, dat bang smth 0.05 0.025 0.01\n",
    "    h = math.sqrt((p*q)/(n+1));\n",
    "    KQ=0;\n",
    "    for i in range(1,n+1):\n",
    "        a= ((i/n)-p)/h;\n",
    "        b= (((i-1)/n)-p)/h;\n",
    "        TP=(norm.cdf(a)-norm.cdf(b))*data2[i-1]; #normcdf thu trong matlab\n",
    "        KQ=KQ+TP;    \n",
    "    KQp = KQ;\n",
    "    return KQp\n",
    "\n",
    "for i in [0.05,0.025,0.01]:\n",
    "    print(\"KQp is:\", KQp(test_lstm_recons_error,0.05),\"with q =\",i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Now select a threshold\n",
    "threshold = best_thres#100.13527662881674\n",
    "q = 0.025\n",
    "KQp_thres = KQp(test_lstm_recons_error, q)\n",
    "\n",
    "print(\"KQp threshold is {}\".format(KQp_thres))\n",
    "idx_detection = return_anomaly_idx_by_threshold(test_lstm_recons_error, KQp_thres)\n",
    "#print(idx_detection)\n",
    "idx_detection_augmented = augment_detected_idx(idx_detection, anomaly_index_lstm)\n",
    "#print(anomaly_index_lstm)\n",
    "#print(idx_detection_augmented)\n",
    "accuracy, precision, recall, F1, n_TP, n_TN, n_FP, n_FN = compute_precision_and_recall(idx_detection_augmented, \n",
    "                                                                       anomaly_index_lstm, \n",
    "                                                                       test_labels_lstm)\n",
    "print(\"\\nPR evaluation using KQE:\")\n",
    "print(\"Accuracy: {}\".format(accuracy))\n",
    "print(\"Precision: {}\".format(precision))\n",
    "print(\"Recall: {}\".format(recall))\n",
    "print(\"F1: {}\".format(F1))\n",
    "print(\"TP: {}\".format(n_TP))\n",
    "print(\"TN: {}\".format(n_TN))\n",
    "print(\"FP: {}\".format(n_FP))\n",
    "print(\"FN: {}\".format(n_FN))\n",
    "\n",
    "print(\"\\nThreshold is {}\".format(threshold))\n",
    "idx_detection = return_anomaly_idx_by_threshold(test_lstm_recons_error, threshold)\n",
    "idx_detection_augmented = augment_detected_idx(idx_detection, anomaly_index_lstm)\n",
    "accuracy, precision, recall, F1, n_TP, n_TN, n_FP, n_FN = compute_precision_and_recall(idx_detection_augmented, \n",
    "                                                                       anomaly_index_lstm, \n",
    "                                                                       test_labels_lstm)\n",
    "print(\"\\nPR evaluation using augmented detection:\")\n",
    "print(\"Accuracy: {}\".format(accuracy))\n",
    "print(\"Precision: {}\".format(precision))\n",
    "print(\"Recall: {}\".format(recall))\n",
    "print(\"F1: {}\".format(F1))\n",
    "print(\"TP: {}\".format(n_TP))\n",
    "print(\"TN: {}\".format(n_TN))\n",
    "print(\"FP: {}\".format(n_FP))\n",
    "print(\"FN: {}\".format(n_FN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "for i in range(1,4):\n",
    "    print(1/i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_detected_indices_into_seq(idx_detection, interval):\n",
    "    detected_seq = []\n",
    "    i = 0\n",
    "    while i < len(idx_detection):\n",
    "        if i == 0:\n",
    "            cur_seq = [idx_detection[i]]\n",
    "            i = i + 1\n",
    "        else:\n",
    "            if idx_detection[i] - idx_detection[i-1] > interval:\n",
    "                detected_seq.append(cur_seq)\n",
    "                cur_seq = [idx_detection[i]]\n",
    "            else:\n",
    "                cur_seq.append(idx_detection[i])\n",
    "                if i == len(idx_detection) - 1:\n",
    "                    detected_seq.append(cur_seq)\n",
    "            i = i + 1\n",
    "    \n",
    "    print(\"Detected {} sequences\".format(len(detected_seq)))\n",
    "    return detected_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_detected_anomalies(idx_detection, interval, dataset, result, detection_method, augmented_flag=1, y_scale=5, y_lim=None):\n",
    "    detected_seq = slice_detected_indices_into_seq(idx_detection, interval=interval)\n",
    "    #t_test = result['t_test']\n",
    "    test = result['test']\n",
    "    t_test = np.array(range(result['test'].shape[0]))\n",
    "    idx_anomaly_test = result['idx_anomaly_test']\n",
    "        \n",
    "    # plot detected sequences\n",
    "    fig, axs = plt.subplots(1, 1, figsize=(18, 5), edgecolor='k')\n",
    "    fig.subplots_adjust(hspace=.4, wspace=.4)\n",
    "    axs.plot(t_test, test)\n",
    "    for j in range(len(idx_anomaly_test)):\n",
    "        if j == 0:\n",
    "            axs.plot(idx_anomaly_test[j] * np.ones(20), np.linspace(-y_scale, y_scale, 20), 'r--', label='true anomalies')\n",
    "        else:\n",
    "            axs.plot(idx_anomaly_test[j] * np.ones(20), np.linspace(-y_scale, y_scale, 20), 'r--')\n",
    "        \n",
    "    for i in range(len(detected_seq)):\n",
    "        for j in detected_seq[i]:\n",
    "            if j == detected_seq[0][0]:\n",
    "                axs.plot((j+interval*2) * np.ones(20), np.linspace(-y_scale, -0.8*y_scale, 20), 'g-', label='detected anomalies')\n",
    "            else:\n",
    "                axs.plot((j+interval*2) * np.ones(20), np.linspace(-y_scale, -0.8*y_scale, 20), 'g-')\n",
    "    \n",
    "    for j in range(len(idx_anomaly_test)):\n",
    "        axs.plot(idx_anomaly_test[j] * np.ones(20), np.linspace(-y_scale, y_scale, 20), 'r--')\n",
    "\n",
    "    for i in range(len(detected_seq)):\n",
    "        interval_x = np.asarray([detected_seq[i][0], detected_seq[i][-1]+interval*2])\n",
    "        interval_y = np.asarray([y_scale,y_scale])\n",
    "        if i == 0:\n",
    "            axs.fill_between(interval_x, interval_y, alpha=0.2, color='y', label='detected anomaly windows')\n",
    "        else:\n",
    "            axs.fill_between(interval_x, interval_y, alpha=0.2, color='y')\n",
    "        interval_y = np.asarray([-y_scale,-y_scale])\n",
    "        axs.fill_between(interval_x, interval_y, alpha=0.2, color='y')\n",
    "    axs.grid(True)\n",
    "    axs.set_xlim(0, len(t_test))\n",
    "    if y_lim is None:\n",
    "        axs.set_ylim(-y_scale, y_scale)\n",
    "    else:\n",
    "        axs.set_ylim(-y_scale, y_lim)\n",
    "#     axs.set_xlabel(\"timestamp (every {})\".format(result['t_unit']))\n",
    "    axs.set_ylabel(\"normalised readings\")\n",
    "    axs.set_title(\"{} dataset test sequence\\n(normalised by train mean {:.4f} and std {:.4f})\\n Detection method: {}\".format(dataset, \n",
    "                                                                                        np.mean(result['train_m']), \n",
    "                                                                                        np.mean(result['train_std']),\n",
    "                                                                                        detection_method))\n",
    "    axs.legend()\n",
    "    savefig(config['result_dir']+'detected_anomalies_{}_aug_{}.pdf'.format(detection_method, augmented_flag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_detected_anomalies(idx_detection_augmented, \n",
    "                        interval=config['l_win']*config['l_seq']/2, \n",
    "                        dataset=dataset, \n",
    "                        result=result, \n",
    "                        detection_method='lstm reconstruction error',\n",
    "                        augmented_flag=1,\n",
    "                        y_scale=5,\n",
    "                        y_lim=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#X_train =\n",
    "#predicted_train =\n",
    "#X_test = \n",
    "#predicted = \n",
    "y_test1 = np.where(test_labels_lstm==1,-1,1) #doi lai label\n",
    "\n",
    "#OCSVM\n",
    "#e=X_train - predicted_train\n",
    "#e = val_lstm_error_original\n",
    "e = train_lstm_error_original\n",
    "nsamples, nx, ny = e.shape\n",
    "d2_e = e.reshape((nsamples,nx*ny))\n",
    "\n",
    "nu = 0.5 #0.0055\n",
    "gamma = 'auto' #1.5\n",
    "from sklearn import svm\n",
    "clf = svm.OneClassSVM(nu=nu, kernel=\"rbf\", gamma=gamma)\n",
    "clf.fit(d2_e)\n",
    "\n",
    "#e_t=X_test - predicted\n",
    "e_t = test_lstm_error_original\n",
    "nsamples, nx, ny = e_t.shape\n",
    "\n",
    "d2_e_t = e_t.reshape((nsamples,nx*ny))\n",
    "y_scores = clf.predict(d2_e_t)\n",
    "\n",
    "precision = precision_score(y_test1, y_scores, pos_label=-1)\n",
    "recall    = recall_score(y_test1, y_scores, pos_label=-1)\n",
    "accuracy = accuracy_score(y_test1, y_scores)\n",
    "f1 = f1_score(y_test1, y_scores, pos_label=-1)\n",
    "print ('OSCVM recons abs: ')\n",
    "print ('Precision : ', precision)\n",
    "print ('Recall: ', recall)\n",
    "print ('F1_score: ', f1)\n",
    "print ('Accuracy : ', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['test'].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 1, -1, -1]\n",
    "b = [1, -1, 1, 1]\n",
    "precision = precision_score(a,b,pos_label=-1)\n",
    "recall = recall_score(a,b,pos_label=-1)\n",
    "print(precision)\n",
    "print(recall)\n",
    "f1 = f1_score(a, b, pos_label=-1)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[1,3,4] + [1,7,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores_idx_anomaly = np.squeeze(np.argwhere(y_scores==-1))\n",
    "idx_augmented = augment_detected_idx(y_scores_idx_anomaly, anomaly_index_lstm)\n",
    "y_scores[idx_augmented] = -1\n",
    "\n",
    "precision = precision_score(y_test1, y_scores, pos_label=-1)\n",
    "recall    = recall_score(y_test1, y_scores, pos_label=-1)\n",
    "accuracy = accuracy_score(y_test1, y_scores)\n",
    "f1 = f1_score(y_test1, y_scores, pos_label=-1)\n",
    "print ('\\nOSCVM recons abs augmented: ')\n",
    "print ('Precision : ', precision)\n",
    "print ('Recall: ', recall)\n",
    "print ('F1_score: ', f1)\n",
    "print ('Accuracy : ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
